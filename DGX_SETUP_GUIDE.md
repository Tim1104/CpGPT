# ðŸš€ DGX æœåŠ¡å™¨ CUDA çŽ¯å¢ƒè®¾ç½®æŒ‡å—

## é—®é¢˜æè¿°

åœ¨ NVIDIA DGX Spark æœºå™¨ä¸Šè¿è¡Œæ—¶ï¼Œæ£€æµ‹åˆ° `CUDA å¯ç”¨: False`ï¼Œè¿™æ˜¯ä¸æ­£å¸¸çš„ã€‚

## ðŸ“‹ è¯Šæ–­æ­¥éª¤

### 1. SSH ç™»å½•åˆ° DGX æœåŠ¡å™¨

```bash
# æ›¿æ¢ä¸ºä½ çš„ DGX æœåŠ¡å™¨åœ°å€å’Œç”¨æˆ·å
ssh username@dgx-server-address
```

### 2. ä¸Šä¼ è¯Šæ–­è„šæœ¬åˆ° DGX

**æ–¹æ³• A: ä½¿ç”¨ scp ä¸Šä¼ **
```bash
# åœ¨ä½ çš„ Mac ä¸Šè¿è¡Œ
cd /Users/wulianghua/Documents/GitHub/CpGPT
scp check_cuda_environment.py username@dgx-server-address:~/
```

**æ–¹æ³• B: åœ¨ DGX ä¸Šç›´æŽ¥åˆ›å»º**
```bash
# SSH åˆ° DGX åŽï¼Œåˆ›å»ºæ–‡ä»¶
cat > check_cuda_environment.py << 'EOF'
# å¤åˆ¶ check_cuda_environment.py çš„å†…å®¹åˆ°è¿™é‡Œ
EOF
```

**æ–¹æ³• C: ä½¿ç”¨ git cloneï¼ˆæŽ¨èï¼‰**
```bash
# åœ¨ DGX ä¸Šè¿è¡Œ
cd ~
git clone https://github.com/yourusername/CpGPT.git
cd CpGPT
```

### 3. åœ¨ DGX ä¸Šè¿è¡Œè¯Šæ–­

```bash
# åœ¨ DGX æœåŠ¡å™¨ä¸Šè¿è¡Œ
python check_cuda_environment.py
# æˆ–
python3 check_cuda_environment.py
```

## ðŸ” é¢„æœŸè¾“å‡ºåˆ†æž

### æƒ…å†µ 1: CUDA å¯ç”¨ï¼ˆæ­£å¸¸ï¼‰

```
âœ… çŠ¶æ€: CUDA çŽ¯å¢ƒæ­£å¸¸
âœ… å¯ä»¥ä½¿ç”¨ 8 ä¸ª GPU è¿›è¡Œè®­ç»ƒ/æŽ¨ç†
```

**è§£å†³æ–¹æ¡ˆ:** 
- ä¿®æ”¹ `935k_zero_shot_inference.py` ä¸­çš„ `USE_CPU = False`
- ç›´æŽ¥è¿è¡Œå³å¯

### æƒ…å†µ 2: PyTorch æ˜¯ CPU ç‰ˆæœ¬ï¼ˆæœ€å¸¸è§ï¼‰

```
âŒ PyTorch æ²¡æœ‰ç¼–è¯‘ CUDA æ”¯æŒï¼ˆCPU ç‰ˆæœ¬ï¼‰
```

**è§£å†³æ–¹æ¡ˆ:** é‡æ–°å®‰è£… GPU ç‰ˆæœ¬çš„ PyTorch

#### æ­¥éª¤ A: æ£€æŸ¥ DGX çš„ CUDA ç‰ˆæœ¬

```bash
# åœ¨ DGX ä¸Šè¿è¡Œ
nvidia-smi
```

æŸ¥çœ‹è¾“å‡ºé¡¶éƒ¨çš„ `CUDA Version`ï¼Œä¾‹å¦‚ï¼š
```
+-----------------------------------------------------------------------------+
| NVIDIA-SMI 525.125.06   Driver Version: 525.125.06   CUDA Version: 12.0   |
+-----------------------------------------------------------------------------+
```

#### æ­¥éª¤ B: å¸è½½å½“å‰ PyTorch

```bash
pip uninstall torch torchvision torchaudio -y
```

#### æ­¥éª¤ C: å®‰è£…åŒ¹é…çš„ GPU ç‰ˆæœ¬

**å¦‚æžœ CUDA ç‰ˆæœ¬æ˜¯ 11.x (å¦‚ 11.7, 11.8):**
```bash
pip install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu118
```

**å¦‚æžœ CUDA ç‰ˆæœ¬æ˜¯ 12.x (å¦‚ 12.0, 12.1):**
```bash
pip install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu121
```

**ä½¿ç”¨ conda (æŽ¨èï¼Œå¦‚æžœ DGX ä½¿ç”¨ conda):**
```bash
# CUDA 11.8
conda install pytorch torchvision torchaudio pytorch-cuda=11.8 -c pytorch -c nvidia

# CUDA 12.1
conda install pytorch torchvision torchaudio pytorch-cuda=12.1 -c pytorch -c nvidia
```

#### æ­¥éª¤ D: éªŒè¯å®‰è£…

```bash
python -c "import torch; print(f'CUDA available: {torch.cuda.is_available()}'); print(f'GPU count: {torch.cuda.device_count()}')"
```

é¢„æœŸè¾“å‡ºï¼š
```
CUDA available: True
GPU count: 8
```

### æƒ…å†µ 3: NVIDIA é©±åŠ¨é—®é¢˜

```
âŒ nvidia-smi æœªæ‰¾åˆ° - NVIDIA é©±åŠ¨å¯èƒ½æœªå®‰è£…
```

**è§£å†³æ–¹æ¡ˆ:** è”ç³» DGX ç®¡ç†å‘˜ï¼Œè¿™éœ€è¦ç³»ç»Ÿçº§åˆ«çš„ä¿®å¤

## ðŸŽ¯ ä¿®æ”¹ 935k è„šæœ¬ä»¥ä½¿ç”¨ GPU

ä¿®å¤ CUDA åŽï¼Œç¼–è¾‘ `examples/935k_zero_shot_inference.py`:

```python
# ç¬¬63è¡Œï¼Œæ”¹ä¸º:
USE_CPU = False  # åœ¨ DGX ä¸Šä½¿ç”¨ GPU

# ç¬¬62è¡Œï¼Œå¯ä»¥å¢žåŠ ï¼ˆDGX å†…å­˜å……è¶³ï¼‰:
MAX_INPUT_LENGTH = 30000  # æˆ–æ›´å¤§
```

## ðŸ“Š DGX ä¼˜åŒ–é…ç½®

åœ¨ DGX ä¸Šï¼Œä½ å¯ä»¥ä½¿ç”¨æ›´æ¿€è¿›çš„é…ç½®ï¼š

```python
# åœ¨ 935k_zero_shot_inference.py ä¸­

# ä½¿ç”¨ GPU
USE_CPU = False

# æ›´å¤§çš„è¾“å…¥é•¿åº¦
MAX_INPUT_LENGTH = 50000  # DGX å†…å­˜å……è¶³

# æ•°æ®åŠ è½½ä¼˜åŒ–
datamodule_age = CpGPTDataModule(
    predict_dir=f"{PROCESSED_DIR}_age",
    dependencies_dir=DEPENDENCIES_DIR,
    batch_size=4,  # å¯ä»¥å¢žåŠ  batch size
    num_workers=8,  # ä½¿ç”¨å¤šä¸ª worker
    max_length=MAX_INPUT_LENGTH,
    dna_llm=config_age.data.dna_llm,
    dna_context_len=config_age.data.dna_context_len,
    sorting_strategy=config_age.data.sorting_strategy,
    pin_memory=True,  # GPU ä¸Šå¯ç”¨
)

# Trainer é…ç½®
trainer = CpGPTTrainer(
    accelerator="gpu",
    devices=1,  # ä½¿ç”¨ 1 ä¸ª GPUï¼Œæˆ– [0,1,2,3] ä½¿ç”¨å¤šä¸ª
    precision="16-mixed",  # æ··åˆç²¾åº¦è®­ç»ƒ
)
```

## ðŸš€ å®Œæ•´è¿è¡Œæµç¨‹ï¼ˆDGXï¼‰

```bash
# 1. SSH åˆ° DGX
ssh username@dgx-server

# 2. æ¿€æ´»çŽ¯å¢ƒï¼ˆå¦‚æžœä½¿ç”¨ conda/venvï¼‰
conda activate your_env
# æˆ–
source venv/bin/activate

# 3. è¿›å…¥é¡¹ç›®ç›®å½•
cd ~/CpGPT

# 4. æ£€æŸ¥ CUDA
python check_cuda_environment.py

# 5. å¦‚æžœ CUDA ä¸å¯ç”¨ï¼Œé‡æ–°å®‰è£… PyTorchï¼ˆè§ä¸Šæ–‡ï¼‰

# 6. ä¿®æ”¹é…ç½®
vim examples/935k_zero_shot_inference.py
# è®¾ç½® USE_CPU = False

# 7. è¿è¡ŒæŽ¨ç†
python examples/935k_zero_shot_inference.py
```

## âš¡ æ€§èƒ½å¯¹æ¯”

| çŽ¯å¢ƒ | é€Ÿåº¦ | æŽ¨èé…ç½® |
|------|------|----------|
| Mac (CPU) | åŸºå‡† | `USE_CPU=True`, `MAX_INPUT_LENGTH=15000` |
| Mac (MPS) | 5-10x | `USE_CPU=False`, `MAX_INPUT_LENGTH=8000` |
| **DGX (GPU)** | **50-100x** | `USE_CPU=False`, `MAX_INPUT_LENGTH=50000` |

## ðŸ› å¸¸è§é—®é¢˜

### Q1: æˆ‘åœ¨ DGX ä¸Šä½†æ˜¯ CUDA è¿˜æ˜¯ä¸å¯ç”¨

**æ£€æŸ¥æ¸…å•:**
1. âœ… ç¡®è®¤ä½ çœŸçš„åœ¨ DGX ä¸Šï¼ˆè¿è¡Œ `hostname`ï¼‰
2. âœ… è¿è¡Œ `nvidia-smi` ç¡®è®¤é©±åŠ¨æ­£å¸¸
3. âœ… æ£€æŸ¥ PyTorch ç‰ˆæœ¬ï¼š`python -c "import torch; print(torch.__version__)"`
4. âœ… ç¡®è®¤ä¸æ˜¯åœ¨ CPU-only çš„ Docker å®¹å™¨ä¸­

### Q2: å®‰è£… GPU ç‰ˆæœ¬ PyTorch åŽè¿˜æ˜¯ä¸è¡Œ

**å¯èƒ½åŽŸå› :**
1. CUDA ç‰ˆæœ¬ä¸åŒ¹é…
2. çŽ¯å¢ƒå˜é‡é—®é¢˜
3. å¤šä¸ª Python çŽ¯å¢ƒæ··æ·†

**è§£å†³æ–¹æ¡ˆ:**
```bash
# å®Œå…¨æ¸…ç†
pip uninstall torch torchvision torchaudio -y
pip cache purge

# é‡æ–°å®‰è£…
pip install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu118

# éªŒè¯
python -c "import torch; print(torch.cuda.is_available())"
```

### Q3: å¦‚ä½•ä½¿ç”¨å¤šä¸ª GPUï¼Ÿ

ä¿®æ”¹ Trainer é…ç½®ï¼š
```python
trainer = CpGPTTrainer(
    accelerator="gpu",
    devices=4,  # ä½¿ç”¨ 4 ä¸ª GPU
    strategy="ddp",  # åˆ†å¸ƒå¼æ•°æ®å¹¶è¡Œ
    precision="16-mixed",
)
```

### Q4: å†…å­˜æº¢å‡ºæ€Žä¹ˆåŠžï¼Ÿ

å³ä½¿åœ¨ DGX ä¸Šä¹Ÿå¯èƒ½é‡åˆ°ï¼Œè§£å†³æ–¹æ¡ˆï¼š
```python
# å‡å° batch_size
batch_size=1

# å‡å° max_length
MAX_INPUT_LENGTH=20000

# ä½¿ç”¨æ¢¯åº¦ç´¯ç§¯
trainer = CpGPTTrainer(
    accumulate_grad_batches=4,  # ç´¯ç§¯ 4 ä¸ª batch
)
```

## ðŸ“ž èŽ·å–å¸®åŠ©

å¦‚æžœé—®é¢˜ä»ç„¶å­˜åœ¨ï¼š
1. è¿è¡Œ `check_cuda_environment.py` å¹¶ä¿å­˜å®Œæ•´è¾“å‡º
2. è¿è¡Œ `nvidia-smi` å¹¶ä¿å­˜è¾“å‡º
3. è¿è¡Œ `pip list | grep torch` æŸ¥çœ‹ PyTorch ç›¸å…³åŒ…
4. è”ç³» DGX ç®¡ç†å‘˜æˆ–æä¾›ä»¥ä¸Šä¿¡æ¯å¯»æ±‚å¸®åŠ©

## ðŸŽ“ å­¦ä¹ èµ„æº

- [PyTorch å®‰è£…æŒ‡å—](https://pytorch.org/get-started/locally/)
- [NVIDIA DGX ç”¨æˆ·æŒ‡å—](https://docs.nvidia.com/dgx/)
- [PyTorch Lightning GPU è®­ç»ƒ](https://lightning.ai/docs/pytorch/stable/accelerators/gpu.html)

