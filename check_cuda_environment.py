#!/usr/bin/env python3
"""
CUDA ç¯å¢ƒè¯Šæ–­è„šæœ¬
ç”¨äºæ£€æŸ¥ PyTorch å’Œ CUDA é…ç½®æ˜¯å¦æ­£ç¡®
"""

import sys
import subprocess

print("=" * 80)
print("ğŸ” CUDA ç¯å¢ƒè¯Šæ–­")
print("=" * 80)

# 1. Python ç‰ˆæœ¬
print("\n1ï¸âƒ£ Python ç‰ˆæœ¬:")
print(f"   {sys.version}")
print(f"   è·¯å¾„: {sys.executable}")

# 2. PyTorch ç‰ˆæœ¬å’Œ CUDA æ”¯æŒ
print("\n2ï¸âƒ£ PyTorch é…ç½®:")
try:
    import torch
    print(f"   âœ“ PyTorch ç‰ˆæœ¬: {torch.__version__}")
    print(f"   âœ“ PyTorch å®‰è£…è·¯å¾„: {torch.__file__}")
    print(f"   âœ“ CUDA å¯ç”¨: {torch.cuda.is_available()}")
    
    if torch.cuda.is_available():
        print(f"   âœ“ CUDA ç‰ˆæœ¬ (PyTorch): {torch.version.cuda}")
        print(f"   âœ“ cuDNN ç‰ˆæœ¬: {torch.backends.cudnn.version()}")
        print(f"   âœ“ GPU æ•°é‡: {torch.cuda.device_count()}")
        for i in range(torch.cuda.device_count()):
            print(f"   âœ“ GPU {i}: {torch.cuda.get_device_name(i)}")
            props = torch.cuda.get_device_properties(i)
            print(f"      - æ˜¾å­˜: {props.total_memory / 1024**3:.2f} GB")
            print(f"      - è®¡ç®—èƒ½åŠ›: {props.major}.{props.minor}")
    else:
        print(f"   âŒ CUDA ä¸å¯ç”¨!")
        print(f"   âš ï¸ PyTorch å¯èƒ½æ˜¯ CPU ç‰ˆæœ¬")
        
        # æ£€æŸ¥æ˜¯å¦ç¼–è¯‘äº† CUDA æ”¯æŒ
        print(f"\n   æ£€æŸ¥ PyTorch ç¼–è¯‘é…ç½®:")
        print(f"   - CUDA ç¼–è¯‘æ”¯æŒ: {torch.version.cuda is not None}")
        if torch.version.cuda is None:
            print(f"   âŒ PyTorch æ²¡æœ‰ç¼–è¯‘ CUDA æ”¯æŒï¼ˆCPU ç‰ˆæœ¬ï¼‰")
        
except ImportError as e:
    print(f"   âŒ PyTorch æœªå®‰è£…: {e}")

# 3. NVIDIA é©±åŠ¨å’Œ CUDA Toolkit
print("\n3ï¸âƒ£ NVIDIA é©±åŠ¨å’Œ CUDA Toolkit:")
try:
    result = subprocess.run(['nvidia-smi'], capture_output=True, text=True, timeout=5)
    if result.returncode == 0:
        print("   âœ“ nvidia-smi å¯ç”¨:")
        # æå–å…³é”®ä¿¡æ¯
        lines = result.stdout.split('\n')
        for line in lines[:15]:  # åªæ˜¾ç¤ºå‰15è¡Œ
            if line.strip():
                print(f"   {line}")
    else:
        print(f"   âŒ nvidia-smi å¤±è´¥: {result.stderr}")
except FileNotFoundError:
    print("   âŒ nvidia-smi æœªæ‰¾åˆ° - NVIDIA é©±åŠ¨å¯èƒ½æœªå®‰è£…")
except subprocess.TimeoutExpired:
    print("   âŒ nvidia-smi è¶…æ—¶")
except Exception as e:
    print(f"   âŒ nvidia-smi é”™è¯¯: {e}")

# 4. CUDA Toolkit ç‰ˆæœ¬
print("\n4ï¸âƒ£ CUDA Toolkit ç‰ˆæœ¬:")
try:
    result = subprocess.run(['nvcc', '--version'], capture_output=True, text=True, timeout=5)
    if result.returncode == 0:
        print("   âœ“ nvcc å¯ç”¨:")
        print(f"   {result.stdout.strip()}")
    else:
        print(f"   âš ï¸ nvcc ä¸å¯ç”¨ï¼ˆå¯èƒ½æœªå®‰è£… CUDA Toolkitï¼‰")
except FileNotFoundError:
    print("   âš ï¸ nvcc æœªæ‰¾åˆ°ï¼ˆCUDA Toolkit å¯èƒ½æœªå®‰è£…æˆ–æœªåœ¨ PATH ä¸­ï¼‰")
except Exception as e:
    print(f"   âš ï¸ nvcc æ£€æŸ¥å¤±è´¥: {e}")

# 5. ç¯å¢ƒå˜é‡
print("\n5ï¸âƒ£ ç›¸å…³ç¯å¢ƒå˜é‡:")
import os
cuda_vars = ['CUDA_HOME', 'CUDA_PATH', 'LD_LIBRARY_PATH', 'PATH']
for var in cuda_vars:
    value = os.environ.get(var, 'æœªè®¾ç½®')
    if var in ['LD_LIBRARY_PATH', 'PATH'] and value != 'æœªè®¾ç½®':
        # åªæ˜¾ç¤º CUDA ç›¸å…³çš„è·¯å¾„
        cuda_paths = [p for p in value.split(':') if 'cuda' in p.lower()]
        if cuda_paths:
            print(f"   {var} (CUDA ç›¸å…³):")
            for p in cuda_paths[:3]:  # åªæ˜¾ç¤ºå‰3ä¸ª
                print(f"      - {p}")
        else:
            print(f"   {var}: (æ—  CUDA ç›¸å…³è·¯å¾„)")
    else:
        print(f"   {var}: {value}")

# 6. å…¶ä»–æ·±åº¦å­¦ä¹ åº“
print("\n6ï¸âƒ£ å…¶ä»–æ·±åº¦å­¦ä¹ åº“:")
libs = [
    ('lightning', 'PyTorch Lightning'),
    ('transformers', 'Hugging Face Transformers'),
    ('numpy', 'NumPy'),
]

for module_name, display_name in libs:
    try:
        module = __import__(module_name)
        version = getattr(module, '__version__', 'æœªçŸ¥ç‰ˆæœ¬')
        print(f"   âœ“ {display_name}: {version}")
    except ImportError:
        print(f"   âš ï¸ {display_name}: æœªå®‰è£…")

# 7. è¯Šæ–­æ€»ç»“
print("\n" + "=" * 80)
print("ğŸ“‹ è¯Šæ–­æ€»ç»“")
print("=" * 80)

try:
    import torch
    if torch.cuda.is_available():
        print("âœ… çŠ¶æ€: CUDA ç¯å¢ƒæ­£å¸¸")
        print(f"âœ… å¯ä»¥ä½¿ç”¨ {torch.cuda.device_count()} ä¸ª GPU è¿›è¡Œè®­ç»ƒ/æ¨ç†")
        print("\nå»ºè®®é…ç½®:")
        print("   - åœ¨ 935k_zero_shot_inference.py ä¸­è®¾ç½®: USE_CPU = False")
        print("   - å¯ä»¥ä½¿ç”¨æ›´å¤§çš„ batch_size å’Œ max_length")
    else:
        print("âŒ çŠ¶æ€: CUDA ä¸å¯ç”¨")
        print("\nå¯èƒ½çš„åŸå› :")
        
        if torch.version.cuda is None:
            print("   1. âŒ PyTorch æ˜¯ CPU ç‰ˆæœ¬ï¼ˆæœ€å¯èƒ½ï¼‰")
            print("      è§£å†³æ–¹æ¡ˆ: é‡æ–°å®‰è£… GPU ç‰ˆæœ¬çš„ PyTorch")
        else:
            print("   1. âš ï¸ NVIDIA é©±åŠ¨é—®é¢˜")
            print("   2. âš ï¸ CUDA Toolkit ç‰ˆæœ¬ä¸åŒ¹é…")
            print("   3. âš ï¸ ç¯å¢ƒå˜é‡é…ç½®é—®é¢˜")
        
        print("\nä¿®å¤æ­¥éª¤:")
        print("   1. æ£€æŸ¥ NVIDIA é©±åŠ¨: nvidia-smi")
        print("   2. å¸è½½å½“å‰ PyTorch: pip uninstall torch torchvision torchaudio")
        print("   3. å®‰è£… GPU ç‰ˆæœ¬ PyTorch (è§ä¸‹æ–¹å‘½ä»¤)")
        
except ImportError:
    print("âŒ çŠ¶æ€: PyTorch æœªå®‰è£…")
    print("\nä¿®å¤æ­¥éª¤:")
    print("   å®‰è£… GPU ç‰ˆæœ¬çš„ PyTorch (è§ä¸‹æ–¹å‘½ä»¤)")

# 8. æ¨èçš„å®‰è£…å‘½ä»¤
print("\n" + "=" * 80)
print("ğŸ”§ æ¨èçš„ PyTorch å®‰è£…å‘½ä»¤")
print("=" * 80)

print("\næ ¹æ®ä½ çš„ CUDA ç‰ˆæœ¬é€‰æ‹©åˆé€‚çš„å‘½ä»¤:")
print("\n# CUDA 11.8 (æ¨è)")
print("pip install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu118")

print("\n# CUDA 12.1")
print("pip install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu121")

print("\n# æˆ–ä½¿ç”¨ conda (æ¨è)")
print("conda install pytorch torchvision torchaudio pytorch-cuda=11.8 -c pytorch -c nvidia")

print("\n# å®‰è£…åéªŒè¯:")
print("python -c \"import torch; print(f'CUDA available: {torch.cuda.is_available()}')\"")

print("\n" + "=" * 80)
print("ğŸ’¡ æç¤º:")
print("   - DGX æœºå™¨é€šå¸¸é¢„è£…äº† CUDAï¼Œæ£€æŸ¥ nvidia-smi è¾“å‡ºçš„ CUDA ç‰ˆæœ¬")
print("   - å®‰è£…ä¸ç³»ç»Ÿ CUDA ç‰ˆæœ¬åŒ¹é…çš„ PyTorch")
print("   - å¦‚æœä¸ç¡®å®šï¼ŒCUDA 11.8 é€šå¸¸å…¼å®¹æ€§æœ€å¥½")
print("=" * 80)

